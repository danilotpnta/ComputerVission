{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport io # Input/Output Module\nimport os # OS interfaces\nimport cv2 # OpenCV package\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport statistics\nimport warnings\n\nfrom urllib import request # module for opening HTTP requests\nfrom matplotlib import pyplot as plt # Plotting library\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport seaborn as sns\nimport statistics\nfrom sklearn.manifold import TSNE\n\nimport sklearn\nfrom sklearn.decomposition import PCA\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.svm import SVC\nfrom scipy.spatial.distance import cdist\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.230891,"end_time":"2021-03-08T07:57:06.335029","exception":false,"start_time":"2021-03-08T07:57:06.104138","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:00:11.497977Z","iopub.execute_input":"2023-04-12T02:00:11.498483Z","iopub.status.idle":"2023-04-12T02:00:23.104155Z","shell.execute_reply.started":"2023-04-12T02:00:11.498444Z","shell.execute_reply":"2023-04-12T02:00:23.102742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"width:100%; height:140px\">\n    <img src=\"https://www.kuleuven.be/internationaal/thinktank/fotos-en-logos/ku-leuven-logo.png/image_preview\" width = 300px, heigh = auto align=left>\n</div>\n\n\nKUL H02A5a Computer Vision: Group Assignment 1\n---------------------------------------------------------------\nStudent numbers: <span style=\"color:red\">r1, r0927846, r3, r4, r5</span>.\n\nThe goal of this assignment is to explore more advanced techniques for constructing features that better describe objects of interest and to perform face recognition using these features. This assignment will be delivered in groups of 5 (either composed by you or randomly assigned by your TA's).\n\nIn this assignment you are a group of computer vision experts that have been invited to ECCV 2021 to do a tutorial about  \"Feature representations, then and now\". To prepare the tutorial you are asked to participate in a kaggle competition and to release a notebook that can be easily studied by the tutorial participants. Your target audience is: (master) students who want to get a first hands-on introduction to the techniques that you apply.\n\n---------------------------------------------------------------\nThis notebook is structured as follows:\n0. Data loading & Preprocessing\n1. Feature Representations\n2. Evaluation Metrics \n3. Classifiers\n4. Experiments\n5. Publishing best results\n6. Discussion\n\nMake sure that your notebook is **self-contained** and **fully documented**. Walk us through all steps of your code. Treat your notebook as a tutorial for students who need to get a first hands-on introduction to the techniques that you apply. Provide strong arguments for the design choices that you made and what insights you got from your experiments. Make use of the *Group assignment* forum/discussion board on Toledo if you have any questions.\n\nFill in your student numbers above and get to it! Good luck! \n\n\n<div class=\"alert alert-block alert-info\">\n<b>NOTE:</b> This notebook is just a example/template, feel free to adjust in any way you please! Just keep things organised and document accordingly!\n</div>\n\n<div class=\"alert alert-block alert-info\">\n<b>NOTE:</b> Clearly indicate the improvements that you make!!! You can for instance use titles like: <i>3.1. Improvement: Non-linear SVM with RBF Kernel.<i>\n</div>\n    \n---------------------------------------------------------------\n# 0. Data loading & Preprocessing\n\n## 0.1. Loading data\nThe training set is many times smaller than the test set and this might strike you as odd, however, this is close to a real world scenario where your system might be put through daily use! In this session we will try to do the best we can with the data that we've got! ","metadata":{"papermill":{"duration":0.022868,"end_time":"2021-03-08T07:57:06.382109","exception":false,"start_time":"2021-03-08T07:57:06.359241","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n\ntrain = pd.read_csv(\n    '/kaggle/input/kul-h02a5a-computer-vision-ga1-2023/train_set.csv', index_col = 0)\ntrain.index = train.index.rename('id')\n\ntest = pd.read_csv(\n    '/kaggle/input/kul-h02a5a-computer-vision-ga1-2023/test_set.csv', index_col = 0)\ntest.index = test.index.rename('id')\n\n# read the images as numpy arrays and store in \"img\" column\ntrain['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-h02a5a-computer-vision-ga1-2023/train/train_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n                for index, row in train.iterrows()]\n\ntest['img'] = [cv2.cvtColor(np.load('/kaggle/input/kul-h02a5a-computer-vision-ga1-2023/test/test_{}.npy'.format(index), allow_pickle=False), cv2.COLOR_BGR2RGB) \n                for index, row in test.iterrows()]\n  \n\ntrain_size, test_size = len(train),len(test)\n\n\"The training set contains {} examples, the test set contains {} examples.\".format(train_size, test_size)","metadata":{"papermill":{"duration":37.543619,"end_time":"2021-03-08T07:57:43.9495","exception":false,"start_time":"2021-03-08T07:57:06.405881","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:00:23.106584Z","iopub.execute_input":"2023-04-12T02:00:23.107358Z","iopub.status.idle":"2023-04-12T02:00:50.800632Z","shell.execute_reply.started":"2023-04-12T02:00:23.107294Z","shell.execute_reply":"2023-04-12T02:00:50.799209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Note: this dataset is a subset of the* [*VGG face dataset*](https://www.robots.ox.ac.uk/~vgg/data/vgg_face/).\n\n## 0.2. A first look\nLet's have a look at the data columns and class distribution.","metadata":{"papermill":{"duration":0.023377,"end_time":"2021-03-08T07:57:43.997466","exception":false,"start_time":"2021-03-08T07:57:43.974089","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# The training set contains an identifier, name, image information and class label\ntrain.head(1)","metadata":{"papermill":{"duration":3.315629,"end_time":"2021-03-08T07:57:47.336913","exception":false,"start_time":"2021-03-08T07:57:44.021284","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T01:00:30.300443Z","iopub.execute_input":"2023-04-11T01:00:30.301081Z","iopub.status.idle":"2023-04-11T01:00:32.680399Z","shell.execute_reply.started":"2023-04-11T01:00:30.301041Z","shell.execute_reply":"2023-04-11T01:00:32.679278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The test set only contains an identifier and corresponding image information.\n\ntest.head(1)","metadata":{"papermill":{"duration":3.283501,"end_time":"2021-03-08T07:57:50.644778","exception":false,"start_time":"2021-03-08T07:57:47.361277","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T01:00:32.683458Z","iopub.execute_input":"2023-04-11T01:00:32.683840Z","iopub.status.idle":"2023-04-11T01:00:35.173653Z","shell.execute_reply.started":"2023-04-11T01:00:32.683803Z","shell.execute_reply":"2023-04-11T01:00:35.172541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The class distribution in the training set:\ntrain.groupby('name').agg({'img':'count', 'class': 'max'})","metadata":{"papermill":{"duration":0.046628,"end_time":"2021-03-08T07:57:50.716317","exception":false,"start_time":"2021-03-08T07:57:50.669689","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T01:00:35.175457Z","iopub.execute_input":"2023-04-11T01:00:35.175842Z","iopub.status.idle":"2023-04-11T01:00:35.192216Z","shell.execute_reply.started":"2023-04-11T01:00:35.175806Z","shell.execute_reply":"2023-04-11T01:00:35.190943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that **Jesse is assigned the classification label 1**, and **Mila is assigned the classification label 2**. The dataset also contains 20 images of **look alikes (assigned classification label 0)** and the raw images. \n\n## 0.3. Preprocess data\n### 0.3.1 Example: HAAR face detector\nIn this example we use the [HAAR feature based cascade classifiers](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html) to detect faces, then the faces are resized so that they all have the same shape. If there are multiple faces in an image, we only take the first one. \n\n<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> You can write temporary files to <code>/kaggle/temp/</code> or <code>../../tmp</code>, but they won't be saved outside of the current session\n</div>\n","metadata":{"papermill":{"duration":0.025108,"end_time":"2021-03-08T07:57:50.766719","exception":false,"start_time":"2021-03-08T07:57:50.741611","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class HAARPreprocessor():\n    \"\"\"Preprocessing pipeline built around HAAR feature based cascade classifiers. \"\"\"\n    \n    def __init__(self, path, face_size):\n        self.face_size = face_size\n        file_path = os.path.join(path, \"haarcascade_frontalface_default.xml\")\n        if not os.path.exists(file_path): \n            if not os.path.exists(path):\n                os.mkdir(path)\n            self.download_model(file_path)\n        \n        self.classifier = cv2.CascadeClassifier(file_path)\n  \n    def download_model(self, path):\n        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/\"\\\n            \"haarcascades/haarcascade_frontalface_default.xml\"\n        \n        with request.urlopen(url) as r, open(path, 'wb') as f:\n            f.write(r.read())\n            \n    def detect_faces(self, img):\n        \"\"\"Detect all faces in an image.\"\"\"\n        \n        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        return self.classifier.detectMultiScale(\n            img_gray,\n            scaleFactor=1.2,\n            minNeighbors=5,\n            minSize=(30, 30),\n            flags=cv2.CASCADE_SCALE_IMAGE\n        )\n        \n    def extract_faces(self, img):\n        \"\"\"Returns all faces (cropped) in an image.\"\"\"\n        \n        faces = self.detect_faces(img)\n\n        return [img[y:y+h, x:x+w] for (x, y, w, h) in faces]\n    \n    def preprocess(self, data_row):\n        faces = self.extract_faces(data_row['img'])\n        \n        # if no faces were found, return None\n        if len(faces) == 0:\n            nan_img = np.empty(self.face_size + (3,))\n            nan_img[:] = np.nan\n            return nan_img\n        \n        # only return the first face\n        return cv2.resize(faces[0], self.face_size, interpolation = cv2.INTER_AREA)\n            \n    def __call__(self, data):\n        return np.stack([self.preprocess(row) for _, row in data.iterrows()]).astype(int)","metadata":{"papermill":{"duration":0.042776,"end_time":"2021-03-08T07:57:50.834913","exception":false,"start_time":"2021-03-08T07:57:50.792137","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:03:44.821084Z","iopub.execute_input":"2023-04-12T02:03:44.821584Z","iopub.status.idle":"2023-04-12T02:03:44.837018Z","shell.execute_reply.started":"2023-04-12T02:03:44.821545Z","shell.execute_reply":"2023-04-12T02:03:44.835439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualise**\n\nLet's plot a few examples.","metadata":{"papermill":{"duration":0.025332,"end_time":"2021-03-08T07:57:50.885849","exception":false,"start_time":"2021-03-08T07:57:50.860517","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# parameter to play with \nFACE_SIZE = (150, 150)\n\ndef plot_image_sequence(data, n, imgs_per_row=7):\n    n_rows = 1 + int(n/(imgs_per_row+1))\n    n_cols = min(imgs_per_row, n)\n\n    f,ax = plt.subplots(n_rows,n_cols, figsize=(10*n_cols,10*n_rows))\n    for i in range(n):\n        if n == 1:\n            ax.imshow(data[i])\n        elif n_rows > 1:\n            ax[int(i/imgs_per_row),int(i%imgs_per_row)].imshow(data[i])\n        else:\n            ax[int(i%n)].imshow(data[i])\n    plt.show()\n\n    \n#preprocessed data \npreprocessor = HAARPreprocessor(path = '../../tmp', face_size=FACE_SIZE)\n\ntrain_X, train_y = preprocessor(train), train['class'].values\ntest_X = preprocessor(test)\n\n","metadata":{"papermill":{"duration":62.263517,"end_time":"2021-03-08T07:58:53.174859","exception":false,"start_time":"2021-03-08T07:57:50.911342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:03:46.354703Z","iopub.execute_input":"2023-04-12T02:03:46.355197Z","iopub.status.idle":"2023-04-12T02:04:50.760169Z","shell.execute_reply.started":"2023-04-12T02:03:46.355157Z","shell.execute_reply":"2023-04-12T02:04:50.758870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filtering imgs that are not faces ONCE\na = train_y[train_y == 1]\nfor i in [6, 12, 15, 18, 27]:\n    np.put(a, i, 0)\ntrain_y[train_y == 1] = a\n\nb = train_y[train_y == 2]\nfor i in [5, 7, 15, 23, 24]:\n    np.put(b, i, 0)\ntrain_y[train_y == 2] = b","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:04:53.741560Z","iopub.execute_input":"2023-04-12T02:04:53.742964Z","iopub.status.idle":"2023-04-12T02:04:53.751707Z","shell.execute_reply.started":"2023-04-12T02:04:53.742899Z","shell.execute_reply":"2023-04-12T02:04:53.750382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot faces of Michael and Sarah\nplot_image_sequence(train_X[train_y == 0], n=len(train_X[train_y == 0]), imgs_per_row=10)","metadata":{"papermill":{"duration":2.635787,"end_time":"2021-03-08T07:58:55.836611","exception":false,"start_time":"2021-03-08T07:58:53.200824","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:46:09.878565Z","iopub.execute_input":"2023-04-11T13:46:09.879457Z","iopub.status.idle":"2023-04-11T13:46:13.807887Z","shell.execute_reply.started":"2023-04-11T13:46:09.879408Z","shell.execute_reply":"2023-04-11T13:46:13.806274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot faces of Jesse\n# 6, 12?, 15, 18, 27\nplot_image_sequence(train_X[train_y == 1], n=len(train_X[train_y == 1]), imgs_per_row=10)","metadata":{"papermill":{"duration":3.840961,"end_time":"2021-03-08T07:58:59.72249","exception":false,"start_time":"2021-03-08T07:58:55.881529","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T01:03:02.615875Z","iopub.execute_input":"2023-04-11T01:03:02.616589Z","iopub.status.idle":"2023-04-11T01:03:14.375278Z","shell.execute_reply.started":"2023-04-11T01:03:02.616551Z","shell.execute_reply":"2023-04-11T01:03:14.372509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot faces of Mila\n# 5?, 7?, 15, 24\nplot_image_sequence(train_X[train_y == 2], n=len(train_X[train_y == 2]), imgs_per_row=10)","metadata":{"papermill":{"duration":3.910256,"end_time":"2021-03-08T07:59:03.703299","exception":false,"start_time":"2021-03-08T07:58:59.793043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:46:26.740926Z","iopub.execute_input":"2023-04-11T13:46:26.742273Z","iopub.status.idle":"2023-04-11T13:46:32.998368Z","shell.execute_reply.started":"2023-04-11T13:46:26.742207Z","shell.execute_reply":"2023-04-11T13:46:32.996874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we are ready to rock!","metadata":{"papermill":{"duration":0.100101,"end_time":"2021-03-08T07:59:04.315571","exception":false,"start_time":"2021-03-08T07:59:04.21547","status":"completed"},"tags":[]}},{"cell_type":"code","source":"val_X = test_X[-100:]\nval_Y = [0, 0, 1, 0, 0, 1, 0, 0, 2, 0,\n         0, 0, 0, 0, 1, 0, 0, 1, 0, 2,\n         2, 0, 2, 0, 0, 1, 1, 0, 0, 1,\n         0, 0, 0, 1, 0, 2, 2, 0, 0, 2,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n         0, 1, 0, 0, 0, 1, 0, 1, 1, 2,\n         0, 0, 0, 0, 1, 0, 2, 0, 2, 1,\n         0, 0, 2, 0, 0, 0, 2, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n         1, 1, 0, 0, 2, 0, 0, 1, 0, 0]\nval_y = np.asarray(val_Y)\nval_y = keras.utils.to_categorical(val_y, num_classes = 3)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:20:03.431311Z","iopub.execute_input":"2023-04-12T02:20:03.431778Z","iopub.status.idle":"2023-04-12T02:20:03.441630Z","shell.execute_reply.started":"2023-04-12T02:20:03.431733Z","shell.execute_reply":"2023-04-12T02:20:03.440290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Feature Representations\n## 1.0. Example: Identify feature extractor\nOur example feature extractor doesn't actually do anything... It just returns the input:\n$$\n\\forall x : f(x) = x.\n$$\n\nIt does make for a good placeholder and baseclass ;).","metadata":{"papermill":{"duration":0.100212,"end_time":"2021-03-08T07:59:04.516059","exception":false,"start_time":"2021-03-08T07:59:04.415847","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class IdentityFeatureExtractor:\n    \"\"\"A simple function that returns the input\"\"\"\n    \n    def transform(self, X):\n        return X\n    \n    def __call__(self, X):\n        return self.transform(X)","metadata":{"papermill":{"duration":0.108781,"end_time":"2021-03-08T07:59:04.725071","exception":false,"start_time":"2021-03-08T07:59:04.61629","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:05:09.267786Z","iopub.execute_input":"2023-04-12T02:05:09.268228Z","iopub.status.idle":"2023-04-12T02:05:09.274916Z","shell.execute_reply.started":"2023-04-12T02:05:09.268189Z","shell.execute_reply":"2023-04-12T02:05:09.273431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.1. Baseline 1: HOG feature extractor/Scale Invariant Feature Transform\n...","metadata":{"papermill":{"duration":0.134288,"end_time":"2021-03-08T07:59:04.959911","exception":false,"start_time":"2021-03-08T07:59:04.825623","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class HOGFeatureExtractor(IdentityFeatureExtractor):\n    \"\"\"TODO: this feature extractor is under construction\"\"\"\n    \n    def __init__(**params):\n        self.params = params\n        \n    def transform(self, X):\n        raise NotImplmentedError","metadata":{"papermill":{"duration":0.110122,"end_time":"2021-03-08T07:59:05.171171","exception":false,"start_time":"2021-03-08T07:59:05.061049","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:05:11.260624Z","iopub.execute_input":"2023-04-12T02:05:11.261036Z","iopub.status.idle":"2023-04-12T02:05:11.266396Z","shell.execute_reply.started":"2023-04-12T02:05:11.261000Z","shell.execute_reply":"2023-04-12T02:05:11.265508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n        \nclass SIFTFeatureExtractor(IdentityFeatureExtractor):\n    \n    def __init__(self, **params):\n        self.params = params\n        self.sift = cv2.SIFT_create(\n                            nfeatures =  self.params.get('nfeatures'),\n                            nOctaveLayers = self.params.get('nOctaveLayers'),\n                            contrastThreshold = self.params.get('contrastThreshold'),\n                            edgeThreshold = self.params.get('edgeThreshold'),\n                            sigma = self.params.get('sigma') )\n        \n    def transform(self, X):        \n        images_descriptors = []\n        for img in X:\n            gray = cv2.cvtColor(img.astype(dtype=np.uint8), cv2.COLOR_BGR2GRAY)\n            _, descriptors = self.sift.detectAndCompute(gray, None)\n            images_descriptors.append(descriptors)\n        return np.asarray(images_descriptors)\n    \n    def flatten(self,image_descriptors):\n        # Filter Nones and flattens array to kx128 dimension\n        all_descriptors = []\n        for descriptors_per_img in image_descriptors:\n            if descriptors_per_img is not None:\n                for e in descriptors_per_img:\n                    all_descriptors.append(e)\n        return all_descriptors\n    \n    def compare_two_img(self, img1, img2):\n        img1 = img1.astype(dtype=np.uint8)\n        img2 = img2.astype(dtype=np.uint8)\n        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n        \n        keypoints1, descriptors1 = self.sift.detectAndCompute(gray1, None)\n        keypoints2, descriptors2 = self.sift.detectAndCompute(gray2, None) \n        \n        if descriptors1 is None: \n            return print('Cannot proceed. Img1 has descriptors: None')\n        if descriptors2 is None:\n            return print('Cannot proceed. Img2 has descriptors: None')\n\n        matches = bf.match(descriptors1,descriptors2)\n        matches = sorted(matches, key = lambda x:x.distance)\n\n        img_matches = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, outImg = np.empty((1,1)))\n        plt.imshow(img_matches)\n    \n    \n    def __call__(self, X):\n        return self.transform(X)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:05:13.138132Z","iopub.execute_input":"2023-04-12T02:05:13.138680Z","iopub.status.idle":"2023-04-12T02:05:13.160873Z","shell.execute_reply.started":"2023-04-12T02:05:13.138632Z","shell.execute_reply":"2023-04-12T02:05:13.159608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparing Matches between Img(s)","metadata":{}},{"cell_type":"code","source":"# Create a SIFT extractor with choosen Hyperameters\n# sift_extractor = SIFTFeatureExtractor() \nsift_extractor = SIFTFeatureExtractor(\n                            nfeatures= 70,\n                            nOctaveLayers = 8,\n                            contrastThreshold = 0.01,\n                            edgeThreshold = 6,\n                            sigma = 0.6)\n\n# Plot the matches between two faces\nsift_extractor.compare_two_img(train_X[12], train_X[17])","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:05:15.612279Z","iopub.execute_input":"2023-04-12T02:05:15.612778Z","iopub.status.idle":"2023-04-12T02:05:16.044446Z","shell.execute_reply.started":"2023-04-12T02:05:15.612742Z","shell.execute_reply":"2023-04-12T02:05:16.043235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.1. t-SNE Plots\n...","metadata":{"papermill":{"duration":0.100377,"end_time":"2021-03-08T07:59:05.372401","exception":false,"start_time":"2021-03-08T07:59:05.272024","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Defining TSNE with same seed for reproducibility\nseed = 42\ntsne = TSNE(random_state = seed, perplexity=15) \n\n# Colours for scatterplot \npalette = sns.color_palette(\"bright\", 3)\n\n# Function for creating a matrix with similarity-based distances between each image\ndef get_distance_matrix(images_descriptors):\n    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n    features = []\n    for (i, descriptors1) in enumerate(images_descriptors):\n        features.append([])\n        for (j, descriptors2) in enumerate(images_descriptors):\n            if i == j:\n                distance = 0\n            elif descriptors1 is None or descriptors2 is None:\n                distance = 999\n            else:\n                matches = bf.match(descriptors1, descriptors2)\n                distance = statistics.mean([match.distance for match in matches])\n\n            features[i].append(distance)\n    return features","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:05:21.822659Z","iopub.execute_input":"2023-04-12T02:05:21.824009Z","iopub.status.idle":"2023-04-12T02:05:21.834565Z","shell.execute_reply.started":"2023-04-12T02:05:21.823951Z","shell.execute_reply":"2023-04-12T02:05:21.832987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining TSNE with same seed for reproducibility\nseed = 42\ntsne = TSNE(random_state = seed, perplexity=15) \n\n# Colours for scatterplot \npalette = sns.color_palette(\"bright\", 3)\n\n# Function for creating a matrix with similarity-based distances between each image\ndef get_distance_matrix(images_descriptors):\n    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n    features = []\n    for (i, descriptors1) in enumerate(images_descriptors):\n        features.append([])\n        for (j, descriptors2) in enumerate(images_descriptors):\n            if i == j:\n                distance = 0\n            elif descriptors1 is None or descriptors2 is None:\n                distance = 999\n            else:\n                matches = bf.match(descriptors1, descriptors2)\n                distance = statistics.mean([match.distance for match in matches])\n\n            features[i].append(distance)\n    return features","metadata":{"papermill":{"duration":0.100308,"end_time":"2021-03-08T07:59:05.57403","exception":false,"start_time":"2021-03-08T07:59:05.473722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-12T02:07:28.374511Z","iopub.execute_input":"2023-04-12T02:07:28.375022Z","iopub.status.idle":"2023-04-12T02:07:28.385210Z","shell.execute_reply.started":"2023-04-12T02:07:28.374974Z","shell.execute_reply":"2023-04-12T02:07:28.383854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defines SIFT extractor with specific hyperparameters\nsift_extractor = SIFTFeatureExtractor(\n                            nfeatures= None,\n                            nOctaveLayers = 4,\n                            contrastThreshold = 0.03,\n                            edgeThreshold = 20,\n                            sigma = 1.8)\n\n# Extracting the features\nall_features = sift_extractor.transform(train_X)\nall_features = get_distance_matrix(all_features)\n\n# Calculates pairs of instances in the new dimensional space\nfeatures_low_dimension = tsne.fit_transform(all_features)\ndf = pd.DataFrame(features_low_dimension, columns=[\"x\",\"y\"])\n\n# Create a Scatter plot\nsns.scatterplot(df, x=\"x\", y=\"y\", hue=train_y, legend='full', palette=palette)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:07:45.479842Z","iopub.execute_input":"2023-04-12T02:07:45.480330Z","iopub.status.idle":"2023-04-12T02:07:52.384891Z","shell.execute_reply.started":"2023-04-12T02:07:45.480290Z","shell.execute_reply":"2023-04-12T02:07:52.383653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.1.2. Discussion\n...","metadata":{"papermill":{"duration":0.100596,"end_time":"2021-03-08T07:59:05.775686","exception":false,"start_time":"2021-03-08T07:59:05.67509","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Looking at the effect of SIFT( nOctaveLayers: 3 Default)\nacc_TSNE = []\nparameter = [3, 2, 4, 5] \n\nfor i in parameter:\n    sift_extractor = SIFTFeatureExtractor(\n                            nfeatures = None,\n                            nOctaveLayers = i,\n                            contrastThreshold = None,\n                            edgeThreshold = None,\n                            sigma = None)\n    \n    all_features = sift_extractor(train_X)\n    all_features = get_distance_matrix(all_features)\n    features_low_dimension = tsne.fit_transform(all_features)\n    df = pd.DataFrame(features_low_dimension, columns=[\"x\",\"y\"])\n    acc_TSNE.append(df)\n\n# Plotting\nf, ax = plt.subplots(1, len(parameter), figsize=(20,4))\nf.suptitle('Effect of varying SIFT-Hyperparameter: nOctaveLayers')\n\nfor i, df in enumerate(acc_TSNE):\n    sns.scatterplot(ax=ax[i], data=df, x=\"x\", y=\"y\", hue=train_y, legend='full', palette=palette)\n    ax[i].set_title(f\"Parameter: {parameter[i]}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:11:36.392709Z","iopub.execute_input":"2023-04-12T02:11:36.393177Z","iopub.status.idle":"2023-04-12T02:11:53.821333Z","shell.execute_reply.started":"2023-04-12T02:11:36.393129Z","shell.execute_reply":"2023-04-12T02:11:53.819949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the effect of SIFT( contrastThreshold = 0.04)\n'''\ncontrastThreshold\tThe contrast threshold used to filter out weak features in semi-uniform (low-contrast) regions. \nThe larger the threshold, the less features are produced by the detector.\n'''\nacc_TSNE = []\nparameter = [None, 0.04, 0.08, 0.05] \n\nfor i in parameter:\n    sift_extractor = SIFTFeatureExtractor(\n                            nfeatures = None,\n                            nOctaveLayers = None,\n                            contrastThreshold = i,\n                            edgeThreshold = None,\n                            sigma = None)\n    \n    all_features = sift_extractor(train_X)\n    all_features = get_distance_matrix(all_features)\n    features_low_dimension = tsne.fit_transform(all_features)\n    df = pd.DataFrame(features_low_dimension, columns=[\"x\",\"y\"])\n    acc_TSNE.append(df)\n\n# Plotting\nf, ax = plt.subplots(1, len(parameter), figsize=(20,4))\nf.suptitle('Effect of  SIFT-Hyperparameters')\n\nfor i, df in enumerate(acc_TSNE):\n    sns.scatterplot(ax=ax[i], data=df, x=\"x\", y=\"y\", hue=train_y, legend='full', palette=palette)\n    ax[i].set_title(f\"Parameter: {parameter[i]}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:13:44.218892Z","iopub.execute_input":"2023-04-12T02:13:44.220321Z","iopub.status.idle":"2023-04-12T02:13:58.705710Z","shell.execute_reply.started":"2023-04-12T02:13:44.220263Z","shell.execute_reply":"2023-04-12T02:13:58.704239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the effect of SIFT( edgeThreshold = 10)\n'''\nedgeThreshold\tThe threshold used to filter out edge-like features.\nThe larger the edgeThreshold, the less features are filtered out (more features are retained).\n'''\nacc_TSNE = []\nparameter = [10, 15, 20, 8] \n\nfor i in parameter:\n    sift_extractor = SIFTFeatureExtractor(\n                            nfeatures = None,\n                            nOctaveLayers = None,\n                            contrastThreshold = None,\n                            edgeThreshold = i,\n                            sigma = None)\n    \n    all_features = sift_extractor(train_X)\n    all_features = get_distance_matrix(all_features)\n    features_low_dimension = tsne.fit_transform(all_features)\n    df = pd.DataFrame(features_low_dimension, columns=[\"x\",\"y\"])\n    acc_TSNE.append(df)\n\n# Plotting\nf, ax = plt.subplots(1, len(parameter), figsize=(20,4))\nf.suptitle('Effect of  SIFT-Hyperparameters')\n\nfor i, df in enumerate(acc_TSNE):\n    sns.scatterplot(ax=ax[i], data=df, x=\"x\", y=\"y\", hue=train_y, legend='full', palette=palette)\n    ax[i].set_title(f\"Parameter: {parameter[i]}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:13:58.707821Z","iopub.execute_input":"2023-04-12T02:13:58.708262Z","iopub.status.idle":"2023-04-12T02:14:17.262433Z","shell.execute_reply.started":"2023-04-12T02:13:58.708220Z","shell.execute_reply":"2023-04-12T02:14:17.261124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the effect of SIFT( sigma = 1.6)\n'''\nsigma\tThe sigma of the Gaussian applied to the input image at the octave #0. If your image is captured with a weak camera with soft \nlenses, you might want to reduce the number.\n'''\nacc_TSNE = []\nparameter = [None, 1.6, 1.3, 1.8] \n\nfor i in parameter:\n    sift_extractor = SIFTFeatureExtractor(\n                            nfeatures = None,\n                            nOctaveLayers = None,\n                            contrastThreshold = None,\n                            edgeThreshold = None,\n                            sigma = i)\n    \n    all_features = sift_extractor(train_X)\n    all_features = get_distance_matrix(all_features)\n    features_low_dimension = tsne.fit_transform(all_features)\n    df = pd.DataFrame(features_low_dimension, columns=[\"x\",\"y\"])\n    acc_TSNE.append(df)\n\n# Plotting\nf, ax = plt.subplots(1, len(parameter), figsize=(20,4))\nf.suptitle('Effect of  SIFT-Hyperparameters')\n\nfor i, df in enumerate(acc_TSNE):\n    sns.scatterplot(ax=ax[i], data=df, x=\"x\", y=\"y\", hue=train_y, legend='full', palette=palette)\n    ax[i].set_title(f\"Parameter: {parameter[i]}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:14:17.263863Z","iopub.execute_input":"2023-04-12T02:14:17.264250Z","iopub.status.idle":"2023-04-12T02:14:34.989504Z","shell.execute_reply.started":"2023-04-12T02:14:17.264214Z","shell.execute_reply":"2023-04-12T02:14:34.987883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training SVM model","metadata":{}},{"cell_type":"markdown","source":"We defined two functions:\n\n- 'kmean_bow' is used to cluster all the features into small groups. For instance, an image will have certain features that will be grouped into similar groups. [[1]](#1)\n\n<img width=\"700\" align=\"center\" src=\"https://raw.githubusercontent.com/danilotpnta/ComputerVission/main/img/2.png\" >\n\n- 'create_features_bow' this is used to calculate the features that will be used to train our model. It calculates the minimum distance of the descriptors of one img with klusters created previously. The minimum distance then between clusters is selected to describe the features of an image.\n\n![Features of an iamge](https://raw.githubusercontent.com/danilotpnta/ComputerVission/main/img/4.png)\n\nIt will escentially look like the img above where the x-axis is the BoW and the frequencies are the histogram that describes uniquely one image. [[2]](#2).\n\n#### References\n<a id=\"1\">[1]</a> \nC 7.1 | Bag Of Visual Words | CNN | Object Detection | Machine learning | EvODN. Available at: https://youtu.be/1_5uuqWXuIA\n\n<a id=\"2\">[2]</a> \nBag of Visual Words Model for Image Classification and Recognition. Available at: : https://kushalvyas.github.io/BOV.html\n","metadata":{}},{"cell_type":"code","source":"# Creating a Bag of Word fromt the descriptors\ndef kmean_bow(all_descriptors, num_cluster):\n    bow_dict = []\n    kmeans = KMeans(n_clusters = num_cluster)\n    kmeans.fit(all_descriptors)\n    bow_dict = kmeans.cluster_centers_\n\n    return bow_dict\n\ndef create_kmean(all_descriptors, num_cluster):\n    kmeans = KMeans(n_clusters = num_cluster)\n    kmeans.fit(all_descriptors)\n    return kmeans\n    \n\n# Creates features from the BoW\ndef create_feature_bow(image_descriptors, BoW, num_cluster):\n\n    X_features = []\n\n    for i in range(len(image_descriptors)):\n        features = np.array([0] * num_cluster)\n\n        if image_descriptors[i] is not None:\n            '''\n            Compare per each image k*descriptors with the BoW\n            BoW shape: (30, 128)\n            One image k*descriptors: (168, 128)\n            '''\n            distance = cdist(image_descriptors[i], BoW, metric='euclidean')\n            \n            # Along 168 distances calculated, get the min index\n            argmin = np.argmin(distance, axis = 1)   \n            \n            for j in argmin:\n                features[j] += 1\n        X_features.append(features)\n        \n    return X_features\n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:17:14.069529Z","iopub.execute_input":"2023-04-12T02:17:14.069995Z","iopub.status.idle":"2023-04-12T02:17:14.079875Z","shell.execute_reply.started":"2023-04-12T02:17:14.069957Z","shell.execute_reply":"2023-04-12T02:17:14.078635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Contains descriptors of 80 without filtering Nones\nimage_descriptors = sift_extractor(train_X)\n\n# Filter Nones and flattens array to kx128 dimension\nall_descriptors = sift_extractor.flatten(image_descriptors)\n\nnum_cluster = 70      \nBoW = kmean_bow(all_descriptors, num_cluster = num_cluster)\nkmeans = create_kmean(all_descriptors, num_cluster = num_cluster)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:17:15.597324Z","iopub.execute_input":"2023-04-12T02:17:15.600004Z","iopub.status.idle":"2023-04-12T02:17:27.411447Z","shell.execute_reply.started":"2023-04-12T02:17:15.599943Z","shell.execute_reply":"2023-04-12T02:17:27.410127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_features = create_feature_bow(image_descriptors, BoW, num_cluster)\nprint(np.array(X_features).shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:18:02.636402Z","iopub.execute_input":"2023-04-12T02:18:02.636871Z","iopub.status.idle":"2023-04-12T02:18:02.688456Z","shell.execute_reply.started":"2023-04-12T02:18:02.636822Z","shell.execute_reply":"2023-04-12T02:18:02.687095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X_features, train_y, test_size = 0.1, random_state = 1)\nprint(\"X_train shape: \", np.array(X_train).shape)\nprint(\"y_train shape: \", np.array(Y_train).shape)\nprint(\"-------------------------------\")\nprint(\"X_test shape: \", np.array(X_test).shape)\nprint(\"y_test shape: \", np.array(Y_test).shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:19:17.582675Z","iopub.execute_input":"2023-04-12T02:19:17.583171Z","iopub.status.idle":"2023-04-12T02:19:17.593986Z","shell.execute_reply.started":"2023-04-12T02:19:17.583122Z","shell.execute_reply":"2023-04-12T02:19:17.592680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mlp = MLPClassifier(verbose=False, max_iter=6000)\nmlp.fit(X_train, Y_train)\n\n# clf = GridSearchCV(mlp2, parameter_space, n_jobs=-1, cv=3)\n# clf.fit(X_train, Y_train)\nmlp_better = MLPClassifier(verbose=False, max_iter=2000, activation='tanh', \n                           alpha=0.0001, hidden_layer_sizes=(50, 50, 50), \n                           learning_rate= 'constant', solver= 'adam')\nmlp_better.fit(X_train, Y_train)\n\n\nkNN = KNeighborsClassifier(n_neighbors = 4, p = 1)\nkNN.fit(X_train,Y_train)\n\nrndForest = RandomForestClassifier(n_estimators=75, random_state=1)\nrndForest.fit(X_train,Y_train)\n\nmodel_svm = SVC(random_state = 1, max_iter = 120)\nmodel_svm.fit(X_train, Y_train)\n\nensemble = VotingClassifier(estimators=[\n    ('mlp', mlp_better), \n    ('kNN', kNN), \n    ('model_svm', model_svm)], voting='hard')\nensemble.fit(X_train, Y_train)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:20:09.686502Z","iopub.execute_input":"2023-04-12T02:20:09.686928Z","iopub.status.idle":"2023-04-12T02:20:10.803287Z","shell.execute_reply.started":"2023-04-12T02:20:09.686893Z","shell.execute_reply":"2023-04-12T02:20:10.801854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('\"mlp\" model: ')\nprint(\"score on training set params: \", mlp.score(X_train, Y_train))\nprint(\"score on testing set params: \", mlp.score(X_test, Y_test))\n\nprint('\\n\"mlp_better\" model: ')\nprint(\"score on training set params: \", mlp_better.score(X_train, Y_train))\nprint(\"score on testing set params: \", mlp_better.score(X_test, Y_test))\n\nprint('\\n\"model_svm\" model: ')\nprint(\"score on training set params: \", model_svm.score(X_train, Y_train))\nprint(\"score on testing set params: \", model_svm.score(X_test, Y_test))\n\nprint('\\n\"kNN\" model: ')\nprint(\"score on training set params: \", kNN.score(X_train, Y_train))\nprint(\"score on testing set params: \", kNN.score(X_test, Y_test))\n\nprint('\\n\"rndForest\" model: ')\nprint(\"score on training set params: \", rndForest.score(X_train, Y_train))\nprint(\"score on testing set params: \", rndForest.score(X_test, Y_test))\n\nprint('\\n\"model_svm\" model: ')\nprint(\"score on training set params: \", model_svm.score(X_train, Y_train))\nprint(\"score on testing set params: \", model_svm.score(X_test, Y_test))\n\nprint('\\n\"ensemble\" model: ')\nprint(\"score on training set params: \", ensemble.score(X_train, Y_train))\nprint(\"score on testing set params: \", ensemble.score(X_test, Y_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:23:46.600788Z","iopub.execute_input":"2023-04-12T02:23:46.601271Z","iopub.status.idle":"2023-04-12T02:23:46.753597Z","shell.execute_reply.started":"2023-04-12T02:23:46.601234Z","shell.execute_reply":"2023-04-12T02:23:46.752444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predicting on miniBatch Val_X","metadata":{}},{"cell_type":"code","source":"# Contains descriptors of 80 without filtering Nones\nimage_descriptors_test = sift_extractor(val_X)\n\n# Filter Nones and flattens array to kx128 dimension\nall_descriptors_test = sift_extractor.flatten(image_descriptors_test)\n\nX_features_Test = create_feature_bow(image_descriptors_test, BoW, num_cluster)\nprint(np.array(X_features_Test).shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:20:15.367038Z","iopub.execute_input":"2023-04-12T02:20:15.367528Z","iopub.status.idle":"2023-04-12T02:20:16.338147Z","shell.execute_reply.started":"2023-04-12T02:20:15.367489Z","shell.execute_reply":"2023-04-12T02:20:16.336668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"score on testing set 'mlp_better' model: \", mlp_better.score(X_features_Test, val_Y))\nprint(\"score on testing set 'model_svm'  model: \", model_svm.score(X_features_Test, val_Y))\nprint(\"score on testing set 'kNN'        model: \", kNN.score(X_features_Test, val_Y))\nprint(\"score on testing set 'rndForest'  model: \", rndForest.score(X_features_Test, val_Y))\nprint(\"score on testing set 'ensemble'   model: \", ensemble.score(X_features_Test, val_Y))","metadata":{"execution":{"iopub.status.busy":"2023-04-12T02:21:39.329809Z","iopub.execute_input":"2023-04-12T02:21:39.330229Z","iopub.status.idle":"2023-04-12T02:21:39.455928Z","shell.execute_reply.started":"2023-04-12T02:21:39.330195Z","shell.execute_reply":"2023-04-12T02:21:39.454182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1.2. Baseline 2: PCA feature extractor\n...","metadata":{"papermill":{"duration":0.101426,"end_time":"2021-03-08T07:59:05.978236","exception":false,"start_time":"2021-03-08T07:59:05.87681","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class PCAFeatureExtractor(IdentityFeatureExtractor):\n    \"\"\"TODO: this feature extractor is under construction\"\"\"\n    \n    def __init__(self, n_components, data):\n        self.n_components = n_components\n        self.data = self.preprocess_data(data)\n        self.mean = np.mean(self.data, axis=0)\n        self.singular, self.eigenfaces = self.compute_vectors()\n        \n    #THIS FUNCTION IS COMPLETELY COPIED BY SCIKIT-LEARN\n    def svd_flip(self, u, v, u_based_decision=True):  \n        if u_based_decision:\n            # columns of u, rows of v\n            max_abs_cols = np.argmax(np.abs(u), axis=0)\n            signs = np.sign(u[max_abs_cols, range(u.shape[1])])\n            u *= signs\n            v *= signs[:, np.newaxis]\n        else:\n            # rows of v, columns of u\n            max_abs_rows = np.argmax(np.abs(v), axis=1)\n            signs = np.sign(v[range(v.shape[0]), max_abs_rows])\n            u *= signs\n            v *= signs[:, np.newaxis]\n        return u, v\n    \n    def compute_vectors(self):\n        data = self.data - self.mean\n        U, S, Vt = np.linalg.svd(data, full_matrices=False)\n        U, Vt = self.svd_flip(U, Vt)\n        eig_vecs = Vt[:self.n_components]\n        #return the singular values and first n eig_vectors\n        return S, eig_vecs\n    \n    def transform(self, X):\n        #transform data into set of features\n        X_gray = self.preprocess_data(X)\n        new_X = X_gray - self.mean\n        return np.dot(new_X, self.eigenfaces.T)\n    \n    def inverse_transform(self, X):\n        #transform set of features into data\n        \n        return np.dot(X, self.eigenfaces) + self.mean\n    \n    \n    def preprocess_data(self, X):\n        \n        X_gray = np.zeros(X.shape[:-1])\n        for i in range(X.shape[0]): \n            X_gray[i] = cv2.cvtColor(X[i].astype(np.uint8), cv2.COLOR_BGR2GRAY) \n            \n        facematrix = []\n        for face in X_gray:\n            facematrix.append(face.flatten())\n        facematrix = np.array(facematrix)\n        \n        return facematrix","metadata":{"papermill":{"duration":0.111032,"end_time":"2021-03-08T07:59:06.191215","exception":false,"start_time":"2021-03-08T07:59:06.080183","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T12:11:25.597063Z","iopub.execute_input":"2023-04-11T12:11:25.600175Z","iopub.status.idle":"2023-04-11T12:11:25.637486Z","shell.execute_reply.started":"2023-04-11T12:11:25.600090Z","shell.execute_reply":"2023-04-11T12:11:25.636018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca1 = PCAFeatureExtractor(5, train_X)\n#THIqueryS IS A TEST FOR THE PCA\nweights = pca1.transform(train_X)\n# Test on out-of-sample image of existing class\nquery = np.expand_dims(test_X[11], axis=0)\n\nprint(query.shape)\nquery_weight = pca1.transform(query)\neuclidean_distance = np.linalg.norm(weights - query_weight, axis=1)\nbest_match = np.argmin(euclidean_distance)\nprint(\"Best match %s with Euclidean distance %f\" % (train_y[best_match], euclidean_distance[best_match]))\n# Visualize\nfig, axes = plt.subplots(1,2,sharex=True,sharey=True,figsize=(8,6))\naxes[0].imshow(query[0], cmap=\"gray\")\naxes[0].set_title(\"Query\")\naxes[1].imshow(train_X[best_match], cmap=\"gray\")\naxes[1].set_title(\"Best match\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:41:40.088405Z","iopub.execute_input":"2023-04-11T13:41:40.088935Z","iopub.status.idle":"2023-04-11T13:41:43.079955Z","shell.execute_reply.started":"2023-04-11T13:41:40.088891Z","shell.execute_reply":"2023-04-11T13:41:43.078707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## choosing the right number of components\n\nThis could be done either by testing different values and choosing the one that leads to greater accuracy or by analyzing the singular values. Each singular value indicates how much information does the corresponding eigenvector contain. From the following plot we notice that after the 5th vector the ammount of information start to decrease less rapidly so a good number of components would probably be around 5. THis could be a good trade-off between number of features and accuracy.","metadata":{}},{"cell_type":"code","source":"#plotting first 15 singular values\nplt.plot(range(15), pca1.singular[:15])","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:41:46.502938Z","iopub.execute_input":"2023-04-11T13:41:46.504297Z","iopub.status.idle":"2023-04-11T13:41:46.701409Z","shell.execute_reply.started":"2023-04-11T13:41:46.504251Z","shell.execute_reply":"2023-04-11T13:41:46.700026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.1. Eigenface Plots\n...","metadata":{"papermill":{"duration":0.100881,"end_time":"2021-03-08T07:59:06.392861","exception":false,"start_time":"2021-03-08T07:59:06.29198","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# fig, axes = plt.subplots(1,4,sharex=True,sharey=True,figsize=(8,10))\n# for i in range(4):\n#     axes[i].imshow(pca1.eigenfaces[i].real.reshape((100,100)), cmap=\"gray\")\n# plt.show()","metadata":{"papermill":{"duration":0.100638,"end_time":"2021-03-08T07:59:06.595002","exception":false,"start_time":"2021-03-08T07:59:06.494364","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:41:51.551466Z","iopub.execute_input":"2023-04-11T13:41:51.551985Z","iopub.status.idle":"2023-04-11T13:41:51.960253Z","shell.execute_reply.started":"2023-04-11T13:41:51.551938Z","shell.execute_reply":"2023-04-11T13:41:51.958590Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # WORK IN PROGRESS\n\n# values = [2, 5, 15, 30, 80]\n# plotPCA = [PCAFeatureExtractor(i, train_X) for i in values]\n# query = test_X[8]\n# fig, axes = plt.subplots(2,3,sharex=True,sharey=True,figsize=(9,6))\n# axes[0][0].imshow(query), cmap=\"gray\")\n# axes[0][0].set_title(\"Original face\")\n# features = [plotPCA[i].transform(query) for i in range(5)]\n# inverse = [plotPCA[i].inverse_transform(features[i]) for i in range(5)]\n# axes[0][1].imshow(inverse[0].reshape((100,100)), cmap=\"gray\")\n# axes[0][1].set_title(\"using 2 eigenfaces\")\n# axes[0][2].imshow(inverse[1].reshape((100,100)), cmap=\"gray\")\n# axes[0][2].set_title(\"using 5 eigenfaces\")\n# axes[1][0].imshow(inverse[2].reshape((100,100)), cmap=\"gray\")\n# axes[1][0].set_title(\"using 15 eigenfaces\")\n# axes[1][1].imshow(inverse[3].reshape((100,100)), cmap=\"gray\")\n# axes[1][1].set_title(\"using 30 eigenfaces\")\n# axes[1][2].imshow(inverse[4].reshape((100,100)), cmap=\"gray\")\n# axes[1][2].set_title(\"using 80 eigenfaces\")","metadata":{"execution":{"iopub.status.busy":"2023-04-11T01:02:18.894209Z","iopub.status.idle":"2023-04-11T01:02:18.894878Z","shell.execute_reply.started":"2023-04-11T01:02:18.894666Z","shell.execute_reply":"2023-04-11T01:02:18.894688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1.2.2. Feature Space Plots\n...","metadata":{"papermill":{"duration":0.101263,"end_time":"2021-03-08T07:59:06.797448","exception":false,"start_time":"2021-03-08T07:59:06.696185","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.101801,"end_time":"2021-03-08T07:59:07.000598","exception":false,"start_time":"2021-03-08T07:59:06.898797","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### 1.2.3. Discussion\n...","metadata":{"papermill":{"duration":0.102099,"end_time":"2021-03-08T07:59:07.204783","exception":false,"start_time":"2021-03-08T07:59:07.102684","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# 2. Evaluation Metrics\n## 2.0. Example: Accuracy\nAs example metric we take the accuracy. Informally, accuracy is the proportion of correct predictions over the total amount of predictions. It is used a lot in classification but it certainly has its disadvantages...","metadata":{"papermill":{"duration":0.10088,"end_time":"2021-03-08T07:59:07.406787","exception":false,"start_time":"2021-03-08T07:59:07.305907","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"papermill":{"duration":1.180116,"end_time":"2021-03-08T07:59:08.688561","exception":false,"start_time":"2021-03-08T07:59:07.508445","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T12:11:31.278819Z","iopub.execute_input":"2023-04-11T12:11:31.279226Z","iopub.status.idle":"2023-04-11T12:11:31.284214Z","shell.execute_reply.started":"2023-04-11T12:11:31.279191Z","shell.execute_reply":"2023-04-11T12:11:31.283220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Classifiers\n## 3.0. Example: The *'not so smart'* classifier\nThis random classifier is not very complicated. It makes predictions at random, based on the distribution obseved in the training set. **It thus assumes** that the class labels of the test set will be distributed similarly to the training set.","metadata":{"papermill":{"duration":0.103749,"end_time":"2021-03-08T07:59:08.894358","exception":false,"start_time":"2021-03-08T07:59:08.790609","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class RandomClassificationModel:\n    \"\"\"Random classifier, draws a random sample based on class distribution observed \n    during training.\"\"\"\n    \n    def fit(self, X, y):\n        \"\"\"Adjusts the class ratio instance variable to the one observed in y. \n\n        Parameters\n        ----------\n        X : tensor\n            Training set\n        y : array\n            Training set labels\n\n        Returns\n        -------\n        self : RandomClassificationModel\n        \"\"\"\n        \n        self.classes, self.class_ratio = np.unique(y, return_counts=True)\n        self.class_ratio = self.class_ratio / self.class_ratio.sum()\n        return self\n        \n    def predict(self, X):\n        \"\"\"Samples labels for the input data. \n\n        Parameters\n        ----------\n        X : tensor\n            dataset\n            \n        Returns\n        -------\n        y_star : array\n            'Predicted' labels\n        \"\"\"\n\n        np.random.seed(0)\n        return np.random.choice(self.classes, size = X.shape[0], p=self.class_ratio)\n    \n    def __call__(self, X):\n        return self.predict(X)\n    ","metadata":{"papermill":{"duration":0.113194,"end_time":"2021-03-08T07:59:09.110222","exception":false,"start_time":"2021-03-08T07:59:08.997028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T01:02:18.898419Z","iopub.status.idle":"2023-04-11T01:02:18.899325Z","shell.execute_reply.started":"2023-04-11T01:02:18.899033Z","shell.execute_reply":"2023-04-11T01:02:18.899063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1. Baseline 1: My favorite classifier\n...","metadata":{"papermill":{"duration":0.101099,"end_time":"2021-03-08T07:59:09.31402","exception":false,"start_time":"2021-03-08T07:59:09.212921","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# TRANSFER LEARNING - Xception, VGG16\n\n\ndef create_model_C(num_classes, input_shape, base_model=0):\n    \n    inputs = keras.Input(shape=input_shape)\n    \n    if base_model == 0:\n        base_model = keras.applications.Xception(\n        weights='imagenet',  \n        input_shape=input_shape,\n        include_top=False)\n        \n        base_model.trainable = False\n        \n        x = keras.applications.xception.preprocess_input(inputs)\n        \n        \n    else: # base_model == 1:\n        base_model = keras.applications.vgg16.VGG16(weights='imagenet', input_shape=input_shape, include_top=False)\n        \n        base_model.trainable = False\n        \n        x = keras.applications.vgg16.preprocess_input(inputs)\n    \n    \n    x = base_model(x, training=False)\n#     x = layers.BatchNormalization()(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(16, activation=\"relu\")(x)\n    x = layers.Dropout(0.2)(x)\n    \n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n    \n    outputs =layers.Dense(units, activation=activation)(x)\n    \n    \n    return {\"model\": keras.Model(inputs, outputs), \n            \"num_classes\": num_classes, \n            \"input_shape\": input_shape}","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:54:39.287092Z","iopub.execute_input":"2023-04-11T12:54:39.287866Z","iopub.status.idle":"2023-04-11T12:54:39.298681Z","shell.execute_reply.started":"2023-04-11T12:54:39.287822Z","shell.execute_reply":"2023-04-11T12:54:39.297104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model_D(num_classes, input_shape):\n    \n    inputs = keras.Input(shape=input_shape)\n    x = layers.LayerNormalization(axis=-1)(inputs)\n    x = layers.Dense(64, activation=\"relu\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(64, activation=\"relu\")(x)\n    x = layers.Dropout(0.1)(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dropout(0.5)(x)\n    \n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n    \n    outputs =layers.Dense(units, activation=activation)(x)\n    \n    \n    return {\"model\": keras.Model(inputs, outputs), \n            \"num_classes\": num_classes, \n            \"input_shape\": input_shape}","metadata":{"execution":{"iopub.status.busy":"2023-04-11T01:02:18.909243Z","iopub.status.idle":"2023-04-11T01:02:18.909913Z","shell.execute_reply.started":"2023-04-11T01:02:18.909698Z","shell.execute_reply":"2023-04-11T01:02:18.909720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DeepLearningModel:\n    \n    def __init__(self, model, num_classes, input_shape):\n        \n        self.model = model\n        self.num_classes = num_classes\n        self.input_shape = input_shape\n    \n    \n    \n    def fit(self, X, y, epoch=10, lr=1e-3, batch_size=4, augment_data=False, val_ds=None):\n        \n        y_OHE = keras.utils.to_categorical(y, num_classes = self.num_classes)\n        \n        if augment_data:\n            \n            datagen = keras.preprocessing.image.ImageDataGenerator(\n                rescale=1./255,\n                rotation_range=40,\n#                 width_shift_range=0.1,\n#                 height_shift_range=0.1,\n#                 shear_range=0.1,\n                zoom_range=0.1,\n                horizontal_flip=True,\n                brightness_range=[0.95, 1.05],\n                fill_mode='nearest')\n            \n        else:\n            datagen = keras.preprocessing.image.ImageDataGenerator()\n        \n            \n            \n        train_data = datagen.flow(x=X, y=y_OHE, batch_size=batch_size, shuffle=False)\n            \n\n#         callbacks = [\n#             keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n#         ]\n        \n        self.model.compile(\n#             optimizer=keras.optimizers.SGD(lr=lr, momentum=0.9),\n            optimizer=keras.optimizers.experimental.AdamW(lr=lr),\n            loss=\"categorical_crossentropy\",\n            metrics=[\"accuracy\"],\n        )\n        \n          # one hot encoded\n            \n        \n\n        return self.model.fit(\n            x=train_data,\n#             y=y_OHE,\n#             batch_size=batch_size,\n            epochs=epoch,\n#             callbacks=callbacks,\n            validation_data=val_ds,\n        )\n    \n        \n    def predict(self, X):\n        pred = self.model.predict(X)\n        return np.argmax(pred, axis=-1)\n\n    def __call__(self, X):\n        return self.predict(X)","metadata":{"papermill":{"duration":0.108542,"end_time":"2021-03-08T07:59:09.525054","exception":false,"start_time":"2021-03-08T07:59:09.416512","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T12:54:34.125934Z","iopub.execute_input":"2023-04-11T12:54:34.126457Z","iopub.status.idle":"2023-04-11T12:54:34.140584Z","shell.execute_reply.started":"2023-04-11T12:54:34.126418Z","shell.execute_reply":"2023-04-11T12:54:34.139073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 SVM","metadata":{}},{"cell_type":"code","source":"class SVM:\n\n    def __init__(self, ensemble=False):\n\n        if not ensemble:\n            self.model = svm.SVC()\n        \n        else:\n            \n            \n            self.params = {'C':[1,10],'gamma':[1,10],'kernel':['rbf', 'linear'], 'decision_function_shape':['ovr']}\n            self.model = sklearn.model_selection.GridSearchCV(svm.SVC(), self.params)\n#             models = list()\n#             models.append(('svm0', svm.SVC(probability=True, kernel=\"rbf\", decision_function_shape='ovr')))\n# #             models.append(('svm1', svm.SVC(probability=True, kernel='poly', degree=1)))\n#             models.append(('svm2', svm.SVC(probability=True, kernel='poly', degree=3)))\n#             models.append(('svm3', svm.SVC(probability=True, kernel='linear')))\n#             models.append(('svm4', svm.SVC(probability=True, kernel='poly', degree=4)))\n# #             models.append(('svm5', svm.NuSVC(probability=True, nu=0.7, kernel='rbf')))\n# #             models.append(('svm6', svm.NuSVC(probability=True, nu=0.5, kernel='rbf')))\n#             self.model = sklearn.ensemble.VotingClassifier(estimators=models, voting='soft')\n\n    \n    def fit(self, X, y):    \n        \n        return self.model.fit(X, y) \n        \n    def predict(self, X):\n\n        return self.model.predict(X)\n    \n    def __call__(self, X):\n        return self.predict(X)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T14:17:24.864784Z","iopub.execute_input":"2023-04-11T14:17:24.865234Z","iopub.status.idle":"2023-04-11T14:17:24.873538Z","shell.execute_reply.started":"2023-04-11T14:17:24.865194Z","shell.execute_reply":"2023-04-11T14:17:24.872660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RandomForest:\n    \n    def __init__(self, n_estimators=100, max_depth=2):\n\n        self.model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=0)\n\n    \n    def fit(self, X, y):\n        \n        \n        \n        return self.model.fit(X, y)\n        \n    def predict(self, X):\n\n        \n        return self.model.predict(X)\n    \n    def __call__(self, X):\n        return self.predict(X)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:22:55.908652Z","iopub.execute_input":"2023-04-11T13:22:55.909284Z","iopub.status.idle":"2023-04-11T13:22:55.917993Z","shell.execute_reply.started":"2023-04-11T13:22:55.909234Z","shell.execute_reply":"2023-04-11T13:22:55.916611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel:\n    \n    def __init__(self, n_estimators=100, max_depth=2):\n\n        models = list()\n        models.append(('svm0', svm.SVC(kernel=\"rbf\", decision_function_shape='ovr')))\n#         models.append(('svm5', svm.SVC(kernel='poly', degree=3)))\n        \n        self.model = sklearn.ensemble.VotingClassifier(estimators=models, voting='hard')\n\n    \n    def fit(self, X, y):\n        \n        \n        \n        return self.model.fit(X, y)\n        \n    def predict(self, X):\n\n        \n        return self.model.predict(X)\n    \n    def __call__(self, X):\n        return self.predict(X)","metadata":{"execution":{"iopub.status.busy":"2023-04-11T13:40:32.904207Z","iopub.execute_input":"2023-04-11T13:40:32.905871Z","iopub.status.idle":"2023-04-11T13:40:32.914725Z","shell.execute_reply.started":"2023-04-11T13:40:32.905819Z","shell.execute_reply":"2023-04-11T13:40:32.913135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Experiments\n<div class=\"alert alert-block alert-info\"> <b>NOTE:</b> Do <i>NOT</i> use this section to keep track of every little change you make in your code! Instead, highlight the most important findings and the major (best) pipelines that you've discovered.  \n</div>\n<br>\n\n## 4.0. Example: basic pipeline\nThe basic pipeline takes any input and samples a label based on the class label distribution of the training set. As expected the performance is very poor, predicting approximately 1/4 correctly on the training set. There is a lot of room for improvement but this is left to you ;). ","metadata":{"papermill":{"duration":0.102942,"end_time":"2021-03-08T07:59:09.730342","exception":false,"start_time":"2021-03-08T07:59:09.6274","status":"completed"},"tags":[]}},{"cell_type":"code","source":"### USING SVM w/ PCA\n\nk = 25\n\n\n# datagen = keras.preprocessing.image.ImageDataGenerator(\n#                 rotation_range=40,\n# #                 width_shift_range=0.1,\n# #                 height_shift_range=0.1,\n# #                 shear_range=0.1,\n#                 horizontal_flip=True,\n#                 brightness_range=[0.7, 1.3],\n#                 fill_mode='nearest',\n#                 dtype=\"uint8\")\n\n# train_data = datagen.flow(x=train_X, y=train_y, batch_size=train_X.shape[0] * 5, shuffle=True)\n# aX, ay = next(train_data)\n\naX, ay = train_X, train_y\n\nfeature_extractor = PCAFeatureExtractor(k, aX)\nclassifier = SVM(False)\n\n# val_ds = (feature_extractor(val_X), np.argmax(val_y, axis=-1))\n\n\nclassifier.fit(feature_extractor(aX), ay)\n\n# model/final pipeline\nmodel = lambda X: classifier(feature_extractor(X))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T17:25:01.663268Z","iopub.execute_input":"2023-04-11T17:25:01.663769Z","iopub.status.idle":"2023-04-11T17:25:02.095750Z","shell.execute_reply.started":"2023-04-11T17:25:01.663723Z","shell.execute_reply":"2023-04-11T17:25:02.093819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ### USING Random Forest w/ PCA\n\n# k = 10\n\n\n# feature_extractor = PCAFeatureExtractor(k, train_X)\n# classifier = RandomForest(n_estimators=200, max_depth=2)\n\n# val_ds = (feature_extractor(val_X), np.argmax(val_y, axis=-1))\n\n\n# classifier.fit(feature_extractor(train_X), train_y)\n\n# # model/final pipeline\n# model = lambda X: classifier(feature_extractor(X))","metadata":{"execution":{"iopub.status.busy":"2023-04-11T14:28:02.431339Z","iopub.execute_input":"2023-04-11T14:28:02.431766Z","iopub.status.idle":"2023-04-11T14:28:03.266444Z","shell.execute_reply.started":"2023-04-11T14:28:02.431728Z","shell.execute_reply":"2023-04-11T14:28:03.265127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate performance of the model on the training set\ntrain_y_star = model(train_X)\nprint(train_y_star)\n\nprint(f\"The performance on the training set is {accuracy_score(train_y, train_y_star):.2f}. This however, does not tell us much about the actual performance (generalisability).\")","metadata":{"papermill":{"duration":0.114717,"end_time":"2021-03-08T07:59:10.480473","exception":false,"start_time":"2021-03-08T07:59:10.365756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T17:25:04.231673Z","iopub.execute_input":"2023-04-11T17:25:04.232103Z","iopub.status.idle":"2023-04-11T17:25:04.277875Z","shell.execute_reply.started":"2023-04-11T17:25:04.232066Z","shell.execute_reply":"2023-04-11T17:25:04.276069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f\"The performance on the training set is {accuracy_score(val_ds[-1], model(val_X)):.2f}. This however, does not tell us much about the actual performance (generalisability).\")","metadata":{"execution":{"iopub.status.busy":"2023-04-11T17:25:06.061676Z","iopub.execute_input":"2023-04-11T17:25:06.062135Z","iopub.status.idle":"2023-04-11T17:25:06.113325Z","shell.execute_reply.started":"2023-04-11T17:25:06.062085Z","shell.execute_reply":"2023-04-11T17:25:06.111111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict the labels for the test set \ntest_y_star = model(test_X)","metadata":{"papermill":{"duration":0.111828,"end_time":"2021-03-08T07:59:10.696438","exception":false,"start_time":"2021-03-08T07:59:10.58461","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:55:10.827820Z","iopub.execute_input":"2023-04-11T13:55:10.828241Z","iopub.status.idle":"2023-04-11T13:55:12.412794Z","shell.execute_reply.started":"2023-04-11T13:55:10.828203Z","shell.execute_reply":"2023-04-11T13:55:12.410995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Publishing best results","metadata":{"papermill":{"duration":0.103853,"end_time":"2021-03-08T07:59:10.903341","exception":false,"start_time":"2021-03-08T07:59:10.799488","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submission = test.copy().drop('img', axis = 1)\nsubmission['class'] = test_y_star\n\nsubmission","metadata":{"papermill":{"duration":0.120392,"end_time":"2021-03-08T07:59:11.127762","exception":false,"start_time":"2021-03-08T07:59:11.00737","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:55:13.921720Z","iopub.execute_input":"2023-04-11T13:55:13.922159Z","iopub.status.idle":"2023-04-11T13:55:13.938954Z","shell.execute_reply.started":"2023-04-11T13:55:13.922121Z","shell.execute_reply":"2023-04-11T13:55:13.937260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv')","metadata":{"papermill":{"duration":0.122516,"end_time":"2021-03-08T07:59:11.356409","exception":false,"start_time":"2021-03-08T07:59:11.233893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-11T13:55:16.105099Z","iopub.execute_input":"2023-04-11T13:55:16.105604Z","iopub.status.idle":"2023-04-11T13:55:16.118060Z","shell.execute_reply.started":"2023-04-11T13:55:16.105556Z","shell.execute_reply":"2023-04-11T13:55:16.116251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Discussion\n...\n\nIn summary we contributed the following: \n* \n","metadata":{"papermill":{"duration":0.116655,"end_time":"2021-03-08T07:59:11.577703","exception":false,"start_time":"2021-03-08T07:59:11.461048","status":"completed"},"tags":[]}}]}